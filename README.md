# CAIS-Winter-Project-Muffin-vs.-Chihuahua-
1. Jonathan Ong
   ongjd@usc.edu

2. The aim of this project was to design a model that could classify images of chihuahuas and muffins. In particular, the goal was to use transfer learning from RESNET18 as a feature extractor to make creating and training the model easier and use less computing power.

3. I used the Muffin vs. Chihuahua dataset on Kaggle (https://www.kaggle.com/datasets/samuelcortinhas/muffin-vs-chihuahua-image-classification). For preprocessing, I resized the all images in the dataset to be 224x224 pixels and normalized all image values according to mean and standard deviation of the images on ImageNet. I chose to take these preprocessing steps because RESNET18 trained on ImageNet images which were all 224x224. So, I transformed the Muffin vs. Chihuahua dataset to match the images the RESNET18 trained on so that the feature extractors (upper layers of RESNET18) would still be valid/applicable. Some of the images in the dataset are grayscale, so I implemented logic to identify grayscale images, and update their tensors to be RGB.

4. For my model architecture, I used RESNET18 as the base. From there, I replaced the last fully connected layer so that it had two outputs (one for muffin and the other for chihuahua). I chose to have two outputs in the final layer instead of one with some sigmoid like function because muffins are not the opposite of chihuahuas. One output with a sigmoid like function would make it so for an image to be more like a muffin, it would have to be less like a chihuahua. For example, if I added blueberries to a picture with a chihuahua, it would be more likely to be a muffin. But, this doesn't make it any less of a chihuahua. Using two outputs in the final layer allows for measures of muffin-ness and chihuahua-ness to vary independently, and I am able to choose the highest value at the end to make a predication.
  Then, I made sure to freeze all layers, except for the fully connected layers. I did this both to speed up training and to preserve RESNET18's feature extractors (early layers). The dataset didn't have enough data to completely train the entire network, but by freezing the network, I was able to only train a small portion of it.
  For hyperparameters, I chose to have 5 epochs and a batch size of 16. I chose to have a batch size of 16 to speed up training (and I remember something about batch size always being a power of 2?). I chose to have 5 epochs to speed up training and hopefully avoid overfitting. Since I wasn't able to implement logic to track loss and stop training when loss stopped decreasing, my model was vulnerable to overfitting if I left it training for too long. So, I settled on a pretty low number of epochs to avoid this. This admittedly is not a perfect solution though, and it would be best to implement logic for early stopping when loss stops decreasing.
  For my loss function, I chose to use binary cross entropy because this was a classification problem between two classes of objects. For my optimizer, I decided to use Adam because it uses decaying momentum, which speeds of training and helps the model get out of local minimums (I also rememebred that Adam was one of the best optimizers from curriculum).

5. For my model I chose to use simple accuracy (# correct/ total). I chose to use simple accuracy (because of time limitations and not being able to figure out much else) and because simple accuracy weighs equally all types of error (false positives and false negatives). This seemed appropriate because in my opinion, classifying a chihuahua as a muffin and a muffin as a chihuahua seem equally inconsequential. My model after training had an accuracy of about 15% on the testing data. This extremely low accuracy had me very suspicious though since it is much worse than pure chance. So, I thought that I might have flipped my labelling in my testModel function. After I flipped my labelling, my model achieved an accuracy of 40%.

6. 
a) 
b) 
c) If I were continue this project, I would like to address some issues in its execution due to me not knowing how to do things or having the time to figure out how to do things. One thing I would like to do is implement logic for early stopping once loss stops decreasing. This would allow me to confortably train the model for more epochs, and possibly give me stronger results. Another thing I would like to implement is data augmentation in the image preprocessing. Since the (smaller) size of the dataset is a limiting factor of the model, I would like to apply data augmentation (random rotations, reflections, etc.) on the images to increase the amount of data my model has to train on.
